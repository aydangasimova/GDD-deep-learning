{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon! \n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to introduce you to a dataset we will be working with during our hackathon. The goal of this hackathon is to put all that you've learned into practice and create your own deep learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pneumonia Classification on X-ray \n",
    "\n",
    "Pneumonia is an infection that inflames the air sacs in one or both lungs, and is visible on an X-ray of the chest. It is your task to create a classifier that can distinguish between an x-ray with pneumonia and a normal x-ray. The data consists of 5,863 images in two categories - pneumonia or normal. \n",
    "\n",
    "The data can be downloaded [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia/download) or found in the `chest_xray` folder in the Dropbox. \n",
    "\n",
    "*The dataset is ~2GB and you will need a Kaggle account to download it*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested procedure\n",
    "You are free to approach this problem the way you like. However, here are a couple of suggested steps to take. \n",
    "\n",
    "* **Visualise your data.**\n",
    "Get a feeling for the data you are dealing with. Is this a difficult problem? Does it seem easy? Do all cases of pneumonia look the same? What is your data distribution of normal vs. not normal? Can you already think of types of data augmentations that might be beneficial, or won't work at all? \n",
    "\n",
    "* **Preprocess your data**\n",
    "Do all images have the same size? Do the values fall within the same ranges? Any other preprocessing steps you can think of? \n",
    "\n",
    "* **Create a simple baseline.**\n",
    "Determine the performance you want to beat. What type of performance metric do you choose? \n",
    "\n",
    "* **Train and evaluate your first model.** \n",
    "When does the model fail? Are there typical mispredicted cases? Is your model complex enough? \n",
    "\n",
    "* **Try transfer learning**\n",
    "Will you use it as a feature extractor or for weight fine-tuning? Experiment with different networks. \n",
    "\n",
    "* **Monitoring**\n",
    "Use Tensorboard for monitoring and to compare models\n",
    "\n",
    "* **Experiment**\n",
    "Try changing settings, the architecture of your model, the model you transfer your weights from, or use some data augmentation techniques. See what happens!\n",
    "\n",
    "Want some inspiration? Take a look at the [Kaggle competition](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) for this dataset. Browse different notebooks under the tab 'notebooks', they can give you inspiration on what preprocessing techniques, models and data augmentation methods to use, and even help you out with reading in the data in the first place. Keep in mind though that this competition is from 2 years ago, when Keras was still a standalone API and not part of Tensorflow. Not all code in these notebooks will be immediately useable (but often replacing 'import keras' with 'import tensorflow.keras' will do the trick).\n",
    "\n",
    "And most of all, have fun! \n",
    "\n",
    "![](../images/pneumonia.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
