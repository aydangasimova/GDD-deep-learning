{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LSTM for human activity recognition\n",
    "\n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "Use an LSTM to classify time series data.\n",
    "\n",
    "## Program\n",
    "\n",
    "- [Exploring the dataset]()\n",
    "- [LSTM Model]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use an LSTM network for time series to classify movements in the [Human Activity Recognition Using Smartphones Data Set](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).\n",
    "\n",
    "The movements can be classified in one of the following six categories:\n",
    "- WALKING,\n",
    "- WALKING_UPSTAIRS,\n",
    "- WALKING_DOWNSTAIRS,\n",
    "- SITTING,\n",
    "- STANDING,\n",
    "- LAYING.\n",
    "\n",
    "This exercise builds on the work from this [LSTM-Human-Activity-Recognition repo](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/README.md).\n",
    "\n",
    "The [original documentation](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) describes the dataset:\n",
    "\n",
    "> Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n",
    "\n",
    "Load UCI HAR train and test data sets.\n",
    "`X_train` and `X_test` are already scaled to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data. \n",
    "data = np.load('../data/UCI_HAR.npz')\n",
    "X_train, Y_train = data['x_train'], data['y_train']\n",
    "X_test, Y_test = data['x_test'], data['y_test']\n",
    "\n",
    "# Gather variables. \n",
    "n_train, timesteps, data_dim = X_train.shape\n",
    "n_classes = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on the model let's explore and explain what the dataset actually contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timesteps, data_dim, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both `X_train` and `Y_train` have 7352 items in it's first dimension. Each item in this dimension can be interpreted as a sample. \n",
    "\n",
    "Each sample in `X_train` consists of readings over time while each sample in the `Y_train` contains the associated label.\n",
    "\n",
    "The idea is that we have a recurrent neural network glide over each timesample in `X_train`,\n",
    "- which has 128 ordered readings (a.k.a. 2.56 seconds at 50 FPS),\n",
    "- of 9 sensor readings (3-axial gyroscope and two 3-axial accelerometers, $ \\rightarrow 3*(x, y, z)$\n",
    "\n",
    "Accelerometer (2x3) and gyroscope (3) = 3x3(x,y,z) = 9\n",
    "to predict a single label from `Y_train` (which can be one of the 6 classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a plot of what this looks like. In the cell below you can select the sample id and view what the data looks like in the `X_train` tensor as well as in the `Y_train` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "title = f\"idx: {idx} class label: {np.argmax(Y_train[idx, :])}\"\n",
    "pd.DataFrame(X_train[idx, :, :]).plot(title=title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You'll also notice that sequential slices from `X_train` actually overlap.\n",
    "\n",
    "![](../images/lstm/overlap-dataset-03-02.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    print(f\"idx: {idx} class label: {np.argmax(Y_train[idx, :])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model\n",
    "\n",
    "### Exercise: Build LSTM model\n",
    "\n",
    "<img src=\"../images/lstm/m_lstm.png\" width=\"500\"/>\n",
    "\n",
    "Implement your own LSTM model based on the TensorFlow model:\n",
    "\n",
    "> - Train model for 5 - 10 epochs while keeping the best model (save to `model_path`) and using early stopping.\n",
    "> - Experiment with\n",
    ">     - a lower batch size\n",
    ">     - a different optimizer\n",
    ">     - more hidden nodes\n",
    ">     - dropout\n",
    "> - Aim for a test accuracy higher than 90%.\n",
    "> - Use a vanilla RNN or multiple LSTM layers, can you get similar performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "m2o_dir = os.path.join('../output', \"m2o\")\n",
    "if os.path.exists(m2o_dir):\n",
    "    shutil.rmtree(m2o_dir)\n",
    "os.makedirs(m2o_dir)\n",
    "\n",
    "model_path = os.path.join(m2o_dir, \"many_to_one.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def make_lstm_model():\n",
    "    \"\"\"Function for making an LSTM model\"\"\"\n",
    "    model = Sequential()\n",
    "    # TODO: fill in\n",
    "    return model\n",
    "\n",
    "\n",
    "np.random.seed(707)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/lstm.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model and get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = make_lstm_model()\n",
    "best_model.load_weights(model_path)\n",
    "\n",
    "probabilities = best_model.predict(X_test)\n",
    "prediction = best_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "class_labels = [\n",
    "    \"WALKING\",\n",
    "    \"WALKING_UPSTAIRS\",\n",
    "    \"WALKING_DOWNSTAIRS\",\n",
    "    \"SITTING\",\n",
    "    \"STANDING\",\n",
    "    \"LAYING\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def plot_classification(truth, prediction, labels=None):\n",
    "    # normalized confusion matrix\n",
    "    truth = truth.argmax(axis=1)\n",
    "    cm = confusion_matrix(truth, prediction)\n",
    "    normalised_cm = np.array(cm, dtype=np.float32) / np.sum(cm) * 100\n",
    "\n",
    "    # show cm matrix accuracy in title\n",
    "    f, ax = plt.subplots(figsize=(6, 6))\n",
    "    cax = ax.imshow(normalised_cm, interpolation=\"nearest\", cmap=plt.cm.rainbow)\n",
    "    f.colorbar(cax)\n",
    "    ax.set_title(\n",
    "        \"normalised confusion matrix\\n{0:.2f}% overall accuracy\".format(\n",
    "            accuracy_score(truth, prediction) * 100\n",
    "        ),\n",
    "        fontsize=16,\n",
    "    )\n",
    "    ax.grid(False)\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(labels, rotation=90)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(labels)\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification(Y_test, prediction, class_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "We've implemented a deep network to recognize human activities.\n",
    "Using multi-dimentional time-features in prediction can be quite challenging, but was a breeze using Keras.\n",
    "Keras also used us to refactor quite lenghty TensorFlow code into only a few commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('../output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
