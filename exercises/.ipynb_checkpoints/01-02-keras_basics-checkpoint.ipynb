{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Basics\n",
    "\n",
    "\n",
    "The goal of this notebook is to familiarize yourself with the Keras sequential API and build your first feed forward neural network. Keras is a high-level Python API for neural networks run on TensorFlow by Google. It was developed with a focus on enabling fast experimentation and runs seamlessly on CPU and GPU. \n",
    "\n",
    "The core data structures of Keras are **layers** and **models**. There are three ways of constructing the model: the [sequential API](https://keras.io/getting-started/sequential-model-guide/), the [functional API](https://keras.io/getting-started/functional-api-guide/) or by [subclassing](https://keras.io/models/about-keras-models/) a keras class. In this notebook, we will focus on the `Sequential` model -- a linear stack of layers.\n",
    "\n",
    "There are many different layers that can be added to the model, including but not limited to Dropout and Dense. The biggest challenge for beginners is to determine which type of layers to use in your model and with what hyperparametes (e.g. number of neurons for your fully-connected Dense layer, or the keep probability of your Dropout layer). This is a topic that we will cover later; for this notebook, the focus is familiarising yourself with the Keras API. \n",
    "\n",
    "Once your model is constructed with all the layers in place, you can compile, train and evaluate it. This is the time to decide your model's hyperparameters, such as the correct loss, optimizer and number of epochs to train for. \n",
    "\n",
    "## A basic example\n",
    "\n",
    "For our basic example, we first generate some random data and then experience the process of creating, defining, compiling, training and evaluating the model. \n",
    "\n",
    "Here's an example of the flow:\n",
    "\n",
    "```python\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile by setting the loss, optimizer and metrics to report.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Start training.\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "\n",
    "# Evaluate.\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras layers and optimizers\n",
    "\n",
    "Before we dive into creating our model, let's have a look at what's available. \n",
    "Let's start with our imports and look what layers and optimizers are available: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Sequential` model API class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import predefined `layers` module and see what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "[layer for layer in dir(layers) if not layer.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the `optimizers` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "[opt for opt in dir(optimizers) if not opt.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many layers and optimizers to choose from! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Build a dummy  model\n",
    "\n",
    "![simple nn](../images/model_diagram.gif)\n",
    "\n",
    "We'll build a simple model with the architecture given in the figure above.\n",
    "The input $\\mathbf{X}$ consists of two variables $\\mathbf{x}_1$ and $\\mathbf{x}_2$ and we'll try to predict a binary class $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with the sequential API. `model` is the container for your network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"DummyModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a model is as easy as adding a layer through the `.add()` method. The layers we add are imported from `keras.layers`. In this case, we create a simple neural network of `Dense` layers (fully-connected layer) and dropout. However, other layer types can be imported and added to our model with the `.add()` method as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each layer you can define the parameters of it.\n",
    "\n",
    "For example, the `Dense()` layer has number of units, its activation function, name, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create the first hidden layer of 3 units with ReLU activation that expects the input to have a dimensionality of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(name=\"FullyConnected_1\", units=3, activation=\"relu\", input_dim=2, use_bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the structure of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** \n",
    "> - Why are there 9 parameters?\n",
    "> - Which other activations could you use? Check out the [list of activations](https://keras.io/activations/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the next hidden layer of 2 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(name=\"FullyConnected_2\", units=2, activation=\"relu\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the output layer of a single unit and use a `sigmoid` activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(name=\"FullyConnected_OutputLayer\", units=1, activation=\"sigmoid\")\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models have to be compiled before training, we need to add:\n",
    "\n",
    "- optimizer\n",
    "- loss function\n",
    "- metrics\n",
    "\n",
    "The optimizer is the algorithm that performs gradient descent.\n",
    "We'll use adam.\n",
    "                \n",
    "The loss function defines the goal of our model.\n",
    "In this case it's binary classification, and the binary crossentropy is the appropriate loss function fot that.\n",
    "\n",
    "The metric(s) set are used to evaluate over the test dataset\n",
    "In addition, a validation test will be performed over each epoch if we define `validation_split` at trainining time.\n",
    "This is very helpful to asses the health of our model (overfitting for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Questions\n",
    ">\n",
    "> - Which other optimizers are available? Check the [list of optimizers](https://keras.io/optimizers/)\n",
    "> - How many losses are there avilable? Check the [list of loss functions](https://keras.io/losses/)\n",
    "> - What other metrics? [List of metrics](https://keras.io/metrics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we done so far?\n",
    "We have defined the architecture of our model and put that in a variable `model`.\n",
    "This model is a blank slate as it hasn't learned anything yet, so let's find some data to train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model is ready to be trained but where is the data?\n",
    "\n",
    "Normally you would look at the data first before creating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moons = pd.read_csv(\"../data/moons.csv\")\n",
    "print(\"(rows, columns):\", moons.shape)\n",
    "moons.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of two coordinates (`x1`, `x2`) describing locations of a point and a class (`y`).\n",
    "The data is not linearly separable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=moons, x=\"x1\", y=\"x2\", hue=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data in two sets, one for training and one for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    moons[[\"x1\", \"x2\"]], moons[\"y\"], test_size=0.1, random_state=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting & scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to fit the model on the data and see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the parameters. \n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=900,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# Evaluate the model. \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# Plot the results.\n",
    "test_pred = X_test.assign(y_pred=y_pred.squeeze())\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x=\"x1\", y=\"x2\", hue=\"y_pred\", data=test_pred, ax=ax)\n",
    "ax.set_title(\"Predictions on test set\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermezzo: Explicit creation of layers\n",
    "\n",
    "The model we created looks like:\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(name=\"FullyConnected_1\", units=3, activation=\"relu\", input_dim=2))\n",
    "model.add(Dense(name=\"FullyConnected_2\", units=2, activation=\"relu\"))\n",
    "model.add(Dense(name=\"FullyConnected_OutputLayer\", units=1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "We could have defined explicitly each of the components:\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "\n",
    "# input layer transformations (none in this case)\n",
    "\n",
    "# 1st hidden layer\n",
    "model.add(Dense(name=\"HiddenLayer_1\", units=3, input_dim=2))\n",
    "model.add(Activation(name=\"ReLu_1\", activation=\"relu\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(name=\"HiddenLayer_2\", units=2))\n",
    "model.add(Activation(name=\"ReLu_2\", activation=\"relu\"))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(name=\"OutputLayer\", units=1))\n",
    "model.add(Activation(name=\"Sigmoid_3\", activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "\n",
    "This explicit creation of every component gives flexibility on the layer order when customizing a deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we've wrapped the model definition in a small function so we can quickly re-create models.\n",
    "We'll use this more often in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = Sequential(name=\"SimpleModel\")\n",
    "    model.add(Dense(name=\"FullyConnected_1\", units=3, activation=\"relu\", input_dim=2))\n",
    "    model.add(Dense(name=\"FullyConnected_2\", units=2, activation=\"relu\"))\n",
    "    model.add(Dense(name=\"FullyConnected_OutputLayer\", units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "def make_explicit_model():\n",
    "    model = Sequential(name=\"ExplicitModel\")\n",
    "\n",
    "    # 1st hidden layer\n",
    "    model.add(Dense(name=\"HiddenLayer_1\", units=3, input_dim=2))\n",
    "    model.add(Activation(name=\"ReLu_1\", activation=\"relu\"))\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    model.add(Dense(name=\"HiddenLayer_2\", units=2))\n",
    "    model.add(Activation(name=\"ReLu_2\", activation=\"relu\"))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(name=\"OutputLayer\", units=1))\n",
    "    model.add(Activation(name=\"Sigmoid_3\", activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_explicit_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Exercise: Make a more complex model for this data\n",
    "> \n",
    "> - 3 hidden dense layers\n",
    "> - 1 final dense layer with sigmoid activation\n",
    "> - add a `Dropout` layer after each dense layer\n",
    "> - use `relu` and `tanh` or other [activation functions](https://keras.io/activations/)\n",
    "> - experiment with batch size and epochs!\n",
    ">\n",
    "> Make sure your test accuracy gets higher than what you saw before!\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overkill_model():\n",
    "    model = Sequential(name=\"OverkillModel\")\n",
    "\n",
    "    # 1st hidden\n",
    "    \n",
    "    # 2nd hidden\n",
    "\n",
    "    # 3rd hidden\n",
    "\n",
    "    # output layer\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/keras_basics_overkill.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Create the model. \n",
    "model = make_overkill_model()\n",
    "\n",
    "# Compile the model. \n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the parameters.\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# Evaluate the model. \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've seen how to build a Keras from the ground up.\n",
    "To create an architecture, instantiate a sequential model and add layers to it.\n",
    "After compiling a model, you're ready to train and validate the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
