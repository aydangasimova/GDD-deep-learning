{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 15, 6\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN forecast of airline passengers\n",
    "\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal \n",
    "\n",
    "- Create a many-to-one RNN in `Keras` using the `SimpleRNN` recurrent layer.\n",
    "- Use callbacks to save models and monitor progress\n",
    "\n",
    "## Data\n",
    "\n",
    "We will consider the 'standard' airline passenger problem.\n",
    "Given a year and a month, the task is to predict the number of international airline passengers in units of 1000.\n",
    "The data ranges from January 1949 to December 1960 or 12 years, with 144 observations.\n",
    "\n",
    "Load the passenger data, it's:\n",
    "\n",
    "> \"International airline passengers: monthly totals in thousands. Jan 1949 to Dec 1960\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers = pd.read_csv('../data/airline_passengers.csv',\n",
    "                         parse_dates=True, \n",
    "                         index_col=0)\n",
    "passengers.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll prepare the dataset for the `RNN`.\n",
    "`y` contains the number of passengers for a given month.\n",
    "`X` is of size $n \\times p$ where $p$ is the number of months looking back (see `LOOK_BACK`) and $n$ is the total number of observations minus the number of months looking back.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_dataset, look_back=1):\n",
    "    df = input_dataset.copy()\n",
    "    \n",
    "    # Add the lookback. \n",
    "    col_name = 't_min_{}'\n",
    "    for i in range(1, look_back+1):\n",
    "        df[col_name.format(i)] = df['passengers'].shift(i)\n",
    "    \n",
    "    # Remove the dates without all features.\n",
    "    df = df.iloc[look_back:]\n",
    "\n",
    "    # Create X and y. \n",
    "    X = df.drop(['passengers'], axis=1)\n",
    "    X = X[X.columns[::-1]]\n",
    "\n",
    "    y = pd.DataFrame(df['passengers'])\n",
    "\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_BACK = 12\n",
    "\n",
    "X, y = create_dataset(passengers, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 18  # months to forecast\n",
    "\n",
    "# preprocess the data and split in train and test sets\n",
    "train_mask = np.array([True] * (len(X) - TEST_SIZE) + [False] * TEST_SIZE)\n",
    "\n",
    "# fit scaler to targets in training set\n",
    "scaler = StandardScaler().fit(y[train_mask])\n",
    "\n",
    "# rescale all data\n",
    "X_train, y_train, X_test, y_test = (\n",
    "    scaler.transform(dataset.values.reshape(-1, 1)).reshape(dataset.shape)\n",
    "    for dataset in [X[train_mask], y[train_mask], X[~train_mask], y[~train_mask]]\n",
    ")\n",
    "test_ix = y[~train_mask].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape input to be [samples, time steps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, :, np.newaxis]\n",
    "X_test = X_test[:, :, np.newaxis]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only have 1 feature (the historical number of passengers in a month)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Many to one\n",
    "\n",
    "> #### Exercise: NNAR forecast of airline passengers in Keras \n",
    ">\n",
    "> The RNN network should have the following design:\n",
    ">\n",
    "> - two hidden `SimpleRNN` layers with **200 and 30 ReLU nodes**\n",
    ">     - what's the difference with the `RNN` layer?  \n",
    ">     - what does the parameter `return_sequences` do? how should you use it for multiple layers?\n",
    ">     - how is the parameter `recurrent_dropout` different to the `Dropout` layer? \n",
    "> - **dropout** layers with fraction **0.2**\n",
    "> - an output layer should with a **single linear node**\n",
    "> - **Adam optimizer** with learning rate of **1e-4** and decay of **1e-2** and **`mse` loss**\n",
    ">     - you'll have to create an [optimizer object](https://keras.io/optimizers/#adam) to specify the learning rate\n",
    "> - use `(LOOK_BACK, 1)` as the input shape for the first layer \n",
    ">\n",
    "> During fitting of the model you should:\n",
    "> \n",
    "> - use the test data for validation during training\n",
    "> - use a batch size of 32\n",
    "> - determine the right amount of epochs to train for\n",
    "> - try to use the following callbacks:\n",
    ">  - `TensorBoard` for checking the progress (write to a file in `ts.m2o_dir`)\n",
    ">  - `ModelCheckpoint` saving best model only (note: make sure you run `utils.clean_create_dir(ts.m2o_dir)` before the fitting \n",
    "> \n",
    "> Train the many-to-one network a couple of times and consider the train and validation losses, what do you notice?\n",
    "> What happens if you use Adam with its 'default' learning rate? What with a different optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "m2o_dir = os.path.join('../output', \"m2o\")\n",
    "if os.path.exists(m2o_dir):\n",
    "    shutil.rmtree(m2o_dir)\n",
    "os.mkdir(m2o_dir)\n",
    "\n",
    "model_path = os.path.join(m2o_dir, \"many_to_one.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def make_m2o_model():\n",
    "    \"\"\"Function for making many-to-one RNN\"\"\"\n",
    "    model = Sequential()\n",
    "    # fill in\n",
    "    return model\n",
    "\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/m2o.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model and get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = load_model(model_path)\n",
    "\n",
    "truth = pd.DataFrame(scaler.inverse_transform(y_test), index=test_ix, columns=[\"truth\"])\n",
    "prediction = pd.DataFrame(\n",
    "    scaler.inverse_transform(best_model.predict(X_test)), index=test_ix, columns=[\"m2o\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def plot_forecast(truth, prediction):\n",
    "    \"\"\"Plot forecast and show MSE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    truth : dataframe\n",
    "        Actual timeseries\n",
    "\n",
    "    prediction : dataframe,\n",
    "        Predicted timeseries\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        plot axis\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "    ax = truth.plot(ax=ax)\n",
    "    ax = prediction.plot(ax=ax)\n",
    "    title = \"Forecast - MSE - \"\n",
    "    legend = [\"truth\"]\n",
    "    for col in prediction:\n",
    "        mse = mean_squared_error(truth.loc[prediction.index], prediction[col])\n",
    "        title += f\"{col}: {mse:1.0f}\"\n",
    "        legend.append(f\"prediction: {col}\")\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(legend)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(truth, prediction);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you got your MSE lower than 1000, you got a pretty good model!\n",
    "We've got a model that is able to predict one timestep in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Many to many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a many-to-one network, we could use a many-to-many architecture to, for example, predict one and two steps in the future instead of only one step.\n",
    "\n",
    "Reshape the data to achieve the many-to-many architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_many = X_train[:-1]\n",
    "X_test_many = X_test[:-1]\n",
    "y_train_many = np.array(list(zip(y_train[:-1, 0], y_train[1:, 0])))[:, :, np.newaxis]\n",
    "y_test_many = np.array(list(zip(y_test[:-1, 0], y_test[1:, 0])))[:, :, np.newaxis]\n",
    "\n",
    "print(X_train_many.shape)\n",
    "print(y_train_many.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convince yourself that the X and y are now in the right format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Exercise: Multi-year NNAR forecast of airline passengers in Keras\n",
    "> \n",
    "> Use a similar architecture to make a many-to-many model. \n",
    "> \n",
    "> - Let the second RNN layer return sequences and use the `Lambda` layer to select the last two observations.\n",
    "> - Use `TimeDistributed(Dense(1))` as the last layer. \n",
    ">    - What is the advantage of using `TimeDistributed(Dense(1))`? Is it different than `Dense(1)` in general? And in this case?\n",
    ">    - Why are we using 1 unit? (Hint: look at `model.summary().`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "help(TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "m2o_dir = os.path.join('../output', \"m2m\")\n",
    "if os.path.exists(m2o_dir):\n",
    "    shutil.rmtree(m2o_dir)\n",
    "os.mkdir(m2o_dir)\n",
    "\n",
    "model_path = os.path.join(m2o_dir, \"many_to_many.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def make_m2m_model():\n",
    "    \"\"\"Function for making many-to-one RNN\"\"\"\n",
    "    model = Sequential()\n",
    "    # fill in\n",
    "    return model\n",
    "\n",
    "\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ../answers/m2m.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(model_path)\n",
    "\n",
    "# Convert truth and predictions to dataframe.\n",
    "truth = pd.DataFrame(\n",
    "    scaler.inverse_transform(y_test_many.reshape(17, 2)),\n",
    "    index=test_ix[:-1],\n",
    "    columns=[\"truth_one_step\", \"truth_two_step\"],\n",
    ")\n",
    "prediction = pd.DataFrame(\n",
    "    scaler.inverse_transform(best_model.predict(X_test_many).reshape(17, 2)),\n",
    "    index=test_ix[:-1],\n",
    "    columns=[\"m2m_one_step\", \"m2m_two_step\"],\n",
    ")\n",
    "\n",
    "# Plot the forecasts.\n",
    "plot_forecast(truth[\"truth_one_step\"], prediction[[\"m2m_one_step\"]]);\n",
    "plot_forecast(truth[\"truth_two_step\"], prediction[[\"m2m_two_step\"]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, both one-step as two-step predictions should follow the truth pretty well.\n",
    "Note that the two-step plot should be moved one step ahead to align with the correct dates.\n",
    "Using multiple tasks like this is called multitask learning and can improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've used recurrent neural networks to solve a typical timeseries problems.\n",
    "Using neural nets allowed us to be flexible in the task that we've solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Exercise\n",
    ">\n",
    "> - Try solving the two-steps prediction with a standard timeseries forecasting tool you're familiar with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
