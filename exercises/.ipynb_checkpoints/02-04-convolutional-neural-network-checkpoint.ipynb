{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "\n",
    "Convolutional Neural Networks are great for image processing tasks. In this notebook, we're going to attempt to build and train a CNN. \n",
    "\n",
    "## The Data\n",
    "The dataset we will be using will be a German Traffic Sign Recognition Benchmark (GTSRB) dataset. The dataset consists of 43 different types of road signs found all throughout Germany, and our goal is to correctly determine which traffic sign we have on our image. \n",
    "\n",
    "Let's start with defining some properties of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder. \n",
    "data_path = Path('../data/GTSRB')\n",
    "\n",
    "# Predefined image height and width. \n",
    "IMG_HEIGHT = 30\n",
    "IMG_WIDTH = 30\n",
    "\n",
    "# Number of classes\n",
    "NUM_CATEGORIES = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's load the data and immediately one-hot-encode the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    '''\n",
    "    Loading data from Train folder.\n",
    "    \n",
    "    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n",
    "    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n",
    "    `labels` is a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    '''\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    for category in range(NUM_CATEGORIES):\n",
    "        category_dir = data_dir / str(category)\n",
    "        for img_file in category_dir.glob('*'): \n",
    "            img = load_img(img_file, target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(category)\n",
    "            \n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data. \n",
    "images, labels = load_data(data_path)\n",
    "\n",
    "# One hot encoding the labels\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize \n",
    "Before we move onto any modelling, let's inspect what kind of images we have in our data. We will create a 7x7 grid as this will fit our 43 categories (with six spaces to spare) and visualise a random instance of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing all the different traffic signs\n",
    "img_dir = pathlib.Path(data_path)\n",
    "plt.figure(figsize=(14,14))\n",
    "index = 0\n",
    "for i in range(NUM_CATEGORIES):\n",
    "    plt.subplot(7, 7, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    sign = list(img_dir.glob(f'{i}/*'))[0]\n",
    "    img = load_img(sign, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "\n",
    "Besides loading in the data, we need to split our data into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Preprocessing\n",
    "Can you think of any preprocessing technique that might apply here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/cnn_preprocessing.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also prepare a train- and evaluation function that will execute the training and evaluation for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_func):\n",
    "    # Create and print model\n",
    "    model = model_func()\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Fitting the model\n",
    "    epochs = 30\n",
    "    model.fit(x_train, \n",
    "              y_train,\n",
    "              validation_data = (x_test, y_test), \n",
    "              epochs=epochs, \n",
    "              batch_size=16\n",
    "             )\n",
    "    \n",
    "    # evaluate\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print('Test set accuracy: ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model\n",
    "\n",
    "It's time to create our first version of a model. Let this model have one convolutional layer. \n",
    "\n",
    "**Exercise**: Create a CNN with one Conv layer and get it to train. Don't worry if the results aren't any good yet!\n",
    "\n",
    "Hints: \n",
    "   * The first convolutional layer must receive an `input_shape`, otherwise it doesn't know what size of images to expect! \n",
    "   * Try to set the `filters`, `kernel_size` and `activation` for your convolutional layer. What values would you think are appropriate? Experiment! \n",
    "   * A CNN always ends with a fully-connected (Dense) layer and the number of categories as output. \n",
    "   * Have you tried going from a Conv2D to Dense immediately? That'll likely lead to an error! In order to be able to use your Dense layer, you must _flatten_ your output feature maps. \n",
    "   \n",
    "Experiment: \n",
    "   * Add another Dense layer at the end. How does this influence the result? Do you understand why? \n",
    "   * Add two more convolutional layers. How does this influence the training time? How does this influence performance? What happens to the number of parameters? \n",
    "   * Experiment with your settings for filters. How does it influence the number of parameters, training time and performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_simple_model(): \n",
    "    # Create your simple model. \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "train_and_evaluate(create_simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial reduction\n",
    "\n",
    "Use the model you build earlier and add spatial reduction - either in the form of max pooling layers or setting the stride of the convolutions.\n",
    "\n",
    "**Exercise**: Build a model with spatial reduction. Try both max pooling and setting the stride. What influence does this have on the number of parameters and the training time? What influence does this have on the final accuracy? Is this what you expect? Can you think of a reason why spatial reduction may be beneficial? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "def create_spatial_reduction_model():\n",
    "    return model\n",
    "\n",
    "train_and_evaluate(create_spatial_reduction_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization \n",
    "\n",
    "Let's expand the previous model with some regularization techniques! Specifically, dropout and batch normalization. \n",
    "\n",
    "#### Dropout\n",
    "Dropout is a technique that prevents that the network becomes too sensitive to the weight of specific neurons. While training, a node may temporarily be deactivated to ensure the contribution of the node is removed. This ensures predictions do not become too dependent on particular neurons. Dropout is generally applied after the non-linearity (ReLU), and it is of the utmost important to deactivate dropout when evaluating the model on the validation or test set. Luckily, Keras handles this for you. \n",
    "\n",
    "In a fully-connected network, a common value for dropout is `0.5`. However, in a convolutional neural network, we prefer to set that value to `0.2-0.3`. Can you think of a reason why? \n",
    "\n",
    "#### Batch Normalization \n",
    "\n",
    "Another layer typically inserted in a convolutional neural network is the Batch Normalization layer. This ensures that the output of the (convolutional) layer takes on a Gaussian distribution (with an initial zero mean and unit variance, that is adjusted throughout the learning process). Batch normalisation decreases the difficulty of training the network and allows the network to be more robust against a bad initial choice of weights.\n",
    "\n",
    "**Exercise**: Introduce Batch Normalization and Dropout into your network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_model():  \n",
    "    model = Sequential()\n",
    "    model.add(...)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_and_evaluate(create_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Final Exercise\n",
    "\n",
    "Create the best model you can! \n",
    "\n",
    "Feel free to experiment with everything you've seen so far. The model architecture (number of layers, hyperparameters of the layers, etc.), but also the training hyperparameters (number of epochs, optimizer, etc.). \n",
    "\n",
    "What kind of data augmentation could help with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "def create_model(): \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "train_and_evaluate(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/final_model_example.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
