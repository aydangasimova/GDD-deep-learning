{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning for image classification\n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "- Use transfer learning to classify images\n",
    "- Learn how to load images from disk\n",
    "\n",
    "## Program\n",
    "\n",
    "- [Pre-trained models available in Keras]()\n",
    "    - [Inception]()\n",
    "    - [MobileNet]()\n",
    "    - [Classifying an image using a pre-trained network]()\n",
    "    \n",
    "    \n",
    "- [The CIFAR-10 dataset]()\n",
    "- [Transfer learning with pre-trained weights]()\n",
    "- [Loading images from disk]()\n",
    "- [Training and validating the model]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-trained models available in Keras\n",
    "\n",
    "There are several pre-trained models for image classification in Keras. Here is a summary:\n",
    "\n",
    "![pre-trained models](../images/transfer_learning/pre_trained_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: Pre-trained models\n",
    "> \n",
    "> Have a look at the documentation about the different pre-trained models https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception V3\n",
    "\n",
    "Inceoption V3 was trained for `imagenet` over 1000 classes. Check the classes it was trained on [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).\n",
    "\n",
    "![inception V3](../images/transfer_learning/inceptionV3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet\n",
    "\n",
    "MobileNet is an architecture trained for `imagenet` over 1000 classes but is lighter weight and mobile-friendly network.\n",
    "Check the classes it was trained on [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).\n",
    "The architecture is given in the table below.\n",
    "\n",
    "<figure style=\"text-align:center;\">\n",
    "    <img src=\"../images/transfer_learning/mobilenet.jpeg\" width=\"700\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify an image using [`MobileNet`](https://keras.io/applications/#mobilenet)\n",
    "\n",
    "The model will try to classify an image given the 1000 classes in [ImageNet](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import decode_predictions\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(weights=\"imagenet\")  # this can take a bit\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on this image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/transfer_learning/scorpion.jpg\"\n",
    "# img_path = \"../transfer_learning/images/dog.jpg\"\n",
    "plt.imshow(mpimg.imread(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpimg.imread(img_path).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default it expects an image of input shape of `(224, 224, 3)`, so we'll process it a bit and then get the top predictions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "best_preds = decode_predictions(preds, top=5)\n",
    "preds = decode_predictions(model.predict(x), top=5)[0]\n",
    "\n",
    "prediction = preds[0][1]\n",
    "certainty = preds[0][2]\n",
    "print(f'The prediction is {prediction} with {certainty:.6f} certainty.\\n')\n",
    "pprint(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise\n",
    ">\n",
    "> * Add your own image to the images folder and check what the predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CIFAR10 \n",
    "\n",
    "MobileNet was trained on ImageNet and we'll re-train it on CIFAR10.\n",
    "CIFAR 10 is a dataset with different image sizes and ten different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "[ax.imshow(random.choice(X_train), cmap=\"gray\") for ax in plt.subplots(1, 6)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a more realistic scenario I'll save the images to disk and we will ingest them from there to the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keras_dataset_to_disk(X_train, y_train, X_test, y_test):\n",
    "    for i, x_img in enumerate(X_train):\n",
    "        label = y_train[i, 0]\n",
    "        train_dir = f\"../output/CIFAR10/train/{label}\"\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        Image.fromarray(x_img).save(os.path.join(train_dir, f\"{i}.jpeg\"))\n",
    "    for i, x_img in enumerate(X_test):\n",
    "        label = y_test[i, 0]\n",
    "        test_dir = f\"../output/CIFAR10/test/{label}\"\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "        Image.fromarray(x_img).save(os.path.join(test_dir, f\"{i}.jpeg\"))\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 1.5 minutes and occupies ~50MB\n",
    "save_keras_dataset_to_disk(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you navigate to `output/CIFAR10/`, you'll find that the directory structure is similar to the one given below.\n",
    "There are two folders for test and train data.\n",
    "Each class has its own subfolder with images belonging to that class in it.\n",
    "This structure allows us to efficiently load images from disk later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "test/\n",
    "    0/\n",
    "        10.jpeg\n",
    "        10008.jpeg\n",
    "        ...\n",
    "        9991.jpeg\n",
    "    1/\n",
    "        10000.jpeg\n",
    "        10022.jpeg\n",
    "        ...\n",
    "        9998.jpeg\n",
    "    ...\n",
    "    9/\n",
    "        1000.jpeg\n",
    "        10030.jpeg\n",
    "        ...\n",
    "        9996.jpeg\n",
    "train/\n",
    "    0/\n",
    "        10.jpeg\n",
    "        1001.jpeg\n",
    "        ...\n",
    "        9991.jpeg\n",
    "    1/\n",
    "        1005.jpeg\n",
    "        1006.jpeg\n",
    "        ...\n",
    "        9998.jpeg\n",
    "    ...\n",
    "    9/\n",
    "        1008.jpeg\n",
    "        1060.jpeg\n",
    "        ...\n",
    "        9971.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranfer Learning with pre-trained weights\n",
    "\n",
    "Without transfer learning you could re-use the architecture, but you would have to optimize all the weights from scratch.\n",
    "Now, we'll keep the weights of all layers except the last layer.\n",
    "This way, we use the convolutional filters learned by the model and only teach it to classify 10 different classes. \n",
    "\n",
    "\n",
    "Load the model without the last classification layer and set input_shape as close as possible to original data. Not all input shapes work, check the [documentation](https://keras.io/applications/#mobilenet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise\n",
    "    \n",
    "Compare the last layers with the full model loaded above. \n",
    "> Which layers are missing? Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the weights for all layers: we want to keep the learned filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: add custom layers for our CIFAR10 dataset problem\n",
    " \n",
    "Using the [`functional` API](https://keras.io/getting-started/functional-api-guide/) you will:\n",
    " \n",
    "> - get the output from the base model\n",
    "> - add `GlobalAveragePooling2D` layer\n",
    "> - add `Dense` layer of 512 units\n",
    "> - add output `Dense` layer with 10 units\n",
    "> - put layers together into custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_RAISES_EXCEPTION\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def make_custom_model(base_model):\n",
    "\n",
    "    # get base model output\n",
    "    x = base_model.output\n",
    "\n",
    "    # add GlobalAveragePooling2D layer\n",
    "\n",
    "    # add Dense layer of 512 units\n",
    "\n",
    "    # add output Dense layer with 10 units and softmax activation function\n",
    "\n",
    "    # put layers together into custom model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_custom_model(base_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/transfer_learning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: Trainable parameters\n",
    ">\n",
    "> Check how many trainable parameters in the summary, does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print only the trainable layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.trainable:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile the model. We're using the categorical crossentropy because we're classifying with multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_custom_model(base_model)\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images from disk\n",
    "\n",
    "We'll use the [`ImageDataGenerator`](https://keras.io/preprocessing/image/) to load images from disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: Initiate the generator\n",
    "Implement [`ImageDataGenerator`](https://keras.io/preprocessing/image/) below such that:\n",
    "> - pixel values are re-scaled in the interval 0 to 1\n",
    "> - the missing pixels are filled with 0 when changing the image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/transfer_image_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Flow `CIFAR10` data from file\n",
    " \n",
    "Implement [`ImageDataGenerator.flow_from_directory`](https://keras.io/preprocessing/image/) such that:\n",
    "> - we read the images from `../output/CIFAR10/train` and `../output/CIFAR10/test`\n",
    "> - the target size is set to 128x128\n",
    "> - ensure shuffle\n",
    "> - and the batch size is set by us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_RAISES_EXCEPTION\n",
    "batch_size = 50\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # fill here\n",
    ")\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    # fill here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../answers/cifar_flow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Exercise: fit using the generator\n",
    "> \n",
    "> Use  [`Sequential.fit`](https://keras.io/models/sequential/) such that:\n",
    "> - we ingest images using the `train_generator`\n",
    "> - train for 5 `epochs`\n",
    "> - use 10 `steps_per_epoch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NBVAL_RAISES_EXCEPTION\n",
    "summary = model.fit(\n",
    "    # fill here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load ../answers/cifar_fit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "We've seen how we can use a pre-trained neural network on a new dataset.\n",
    "In addition, we have learned to efficiently load images from disk with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
