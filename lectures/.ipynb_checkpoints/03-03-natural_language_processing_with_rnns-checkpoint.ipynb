{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "WORDS = [\"code\", \"console\", \"cry\", \"cat\", \"dog\"]\n",
    "DOCUMENTS = ['\"code console\"', '\"cry cat\"', '\"dog\"']\n",
    "EMBEDDINGS = [\"embedding_0\", \"embedding_1\"]\n",
    "def one_hot_encoding():\n",
    "    has = [\"has_\" + w for w in WORDS]\n",
    "    return pd.DataFrame(np.eye(len(WORDS), dtype=int), WORDS, columns=has)\n",
    "def one_hot_document():\n",
    "    has = [\"has_\" + w for w in WORDS]\n",
    "    return pd.DataFrame(\n",
    "        [[1, 1, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 1]],\n",
    "        index=DOCUMENTS,\n",
    "        columns=has,\n",
    "    )\n",
    "def embedding_encoding():\n",
    "    return pd.DataFrame(\n",
    "        [[0, 0.2, 0.5, 0.7, 0.8], [0.1, 0.1, 0.4, 0.6, 0.7]],\n",
    "        index=EMBEDDINGS,\n",
    "        columns=[\"code\", \"console\", \"cry\", \"cat\", \"dog\"],\n",
    "    ).T\n",
    "def embedding_document():\n",
    "    return pd.DataFrame(\n",
    "        [[0.1, 0.1], [0.6, 0.5], [0.8, 0.7]], index=DOCUMENTS, columns=EMBEDDINGS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural language processing for RNNs\n",
    "\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One-hot encoding vs embeddings\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One-hot encoding\n",
    "\n",
    "- Traditional style of encoding\n",
    "- Represents words as a big vectors with zeros and ones.\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Disadvantages\n",
    "\n",
    "- Big and sparse vector space\n",
    "- Too many features to learn from\n",
    "- Not enough samples to understand every feature\n",
    "- Treating words as atomic units throws away a lot of information\n",
    "- Doesn't capture relations between words\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A better representation\n",
    "\n",
    "Smaller and dense vector space\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Advantages\n",
    "\n",
    "- Less features to learn from\n",
    "- Points in space close to each other are similar\n",
    "- Relations captured in dimensions\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Embeddings layer\n",
    "\n",
    "- Dense layer that maps one-hot vectors to smaller space\n",
    "- Relations ~ distances\n",
    "- Directions ~ semantic relationships\n",
    "\n",
    "<img src=\"../images/linear-relationships.png\" style=\"width: 50%; display: block; margin-left: auto !important; margin-right: auto !important;\" align=\"center\"/>  \n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Word2Vec\n",
    "\n",
    "Algorithm that learns embeddings by __predicting word contexts__ for a word.\n",
    "\n",
    "Given a word, $\\textsf{vegetable}$, and any other word $ w \\in V $ predict the probability that $ w $ occurs in the context of $\\textsf{vegetable}$:\n",
    "\n",
    "$$P (w | \\textsf{vegetable})$$\n",
    "\n",
    "This approach is unsupervised or __self-supervised__: there's no need for class labels because the (self-)supervision comes from the context.\n",
    "\n",
    "> <font face=\"verdana\">the carrot is <span style=\"background-color: #9ce59e\">a root</span><span style=\"background-color: #fcc86f\"> vegetable</span><span style=\"background-color: #9ce59e\">, usually orange</span></font>\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Word2Vec is a shallow network\n",
    "\n",
    "\n",
    "<img src=\"../images/single-target-single-context.png\" style=\"width: 60%;\"/>\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Look up word vectors and compare them\n",
    "\n",
    "The probability of a context word $w_j$ given a target $w_I$ looks like:\n",
    "\n",
    "$$p(w_j |w_I) = \\frac{\\exp{( u_j )}}{\\sum_{j' \\in V, j' \\neq j} \\exp ( u_j ) }$$\n",
    "\n",
    "where\n",
    "\n",
    "$$u_j=\\mathbf{v}_{w_j}' \\mathbf{h}=\\mathbf{v}_{w_j}' \\mathbf{v}_{w_I}^T$$\n",
    "\n",
    "<img src=\"../images/word2vec_output_weights_function.png\" style=\"width: 70%;\"/>\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: fastText\n",
    "\n",
    "Efficient learning of word representations and sentence classification.\n",
    "\n",
    "Uses the aggregation of word (or N-gram) embeddings as input to a NN classifier.\n",
    "\n",
    "Simple architecture but its performance for sentiment analysis and tag prediction is on par with complexer models (e.g. char-CRNN) and it's much faster. \n",
    "\n",
    "<img src=\"../images/fasttext.png\" style=\"width: 55%;\"/>\n",
    "\n",
    "> Source: [Joulin, 2016]\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RNNs are a natural fit for sequences\n",
    "\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feed-forward üíî sequences\n",
    "\n",
    "We need a different kind of unit!\n",
    "\n",
    "<img src=\"../images/feedforward-sequence.png\" style=\"width: 25%; display: block; margin-left: auto !important; margin-right: auto !important;\" align=\"center\"/>  \n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recurrent ‚ù§Ô∏è sequences\n",
    "\n",
    "Internal loop feeds back the previous state \n",
    "\n",
    "<img src=\"../images/rnn-architecture.png\" style=\"width: 80%; display: block; margin-left: auto !important; margin-right: auto !important;\" align=\"center\"/>  \n",
    "\n",
    "Example: understanding a document\n",
    "-  final score $\\mathbf{h}^{(T)}$ represents what the neural network has learned about the document.\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Document retrieval\n",
    "\n",
    "Architecture to match questions to answers:\n",
    "\n",
    "<img src=\"../images/rnn-retrieval.png\" style=\"width: 40%;\"/>\n",
    "\n",
    "![footer_logo](../images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Document retrieval\n",
    "\n",
    "Example: chatbot using an encoder and decoder:\n",
    "\n",
    "<img src=\"../images/seq2seq-chatbot.png\" style=\"width: 90%;\"/>\n",
    "\n",
    "\n",
    "![footer_logo](../images/logo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example & exercise\n",
    "\n",
    "[Sentiment analysis](../exercises/03-03-nlp_sentiment_classification.ipynb)\n",
    "\n",
    "\n",
    "<img src=\"../images/sentiment-neuron.gif\" style=\"width: 80%; display: block; margin-left: auto !important; margin-right: auto !important;\" align=\"center\"/>  \n",
    "\n",
    "    \n",
    "![footer_logo](../images/logo.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
