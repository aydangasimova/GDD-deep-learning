{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "![footer_logo](../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "Understand the effect of applying a convolution on an image.\n",
    "\n",
    "## Program\n",
    "\n",
    "We will first discuss what a convolution is (and a cross-correlation)\n",
    "\n",
    "- [Convolutions]()\n",
    "\n",
    "We shall then discuss some simple operations and padding\n",
    "\n",
    "- [Identity operation]()\n",
    "- [Translation]()\n",
    "- [Padding]()\n",
    "\n",
    "Afterwards we shall demonstrate some common operations on an image file and discuss the limitations.\n",
    "\n",
    "- [Example operations]()\n",
    "- [Limitations]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.signal import convolve, correlate2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convolutions\n",
    "\n",
    "A convolution operation on an input image is the process of producing an output by\n",
    "combing each pixel of an image with its local neighbours, weighted by a kernel. \n",
    "\n",
    "Imagine an input I with convolution kernel K. The value for a position i in the output can be specified\n",
    "as $V_i = ∑ I_{i+k−j}K_j$, where j is the index over the kernel and k the center position of the j\n",
    "kernel.\n",
    "\n",
    "Intuitively, it can be seen as calculating the dot product between input I and the $180^o$ degree rotation of kernel K. \n",
    "\n",
    "However, in practice, most deep learning algorithms/frameworks do not actually bother with the $180^o$ degree rotation. This means we are actually performing a **cross-correlation**.\n",
    "\n",
    "![](../images/convolutions/convolution_schematic.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity operation\n",
    "A simple example of a convolution is that of the identity operation. The figure shows how a 3 × 3 convolution kernel can be used as an identity operator to produce an output value for the center position. As all weights besides that of the center position are zero, these do not contribute towards the output value, whereas the center value does.\n",
    "\n",
    "![](../images/convolutions/identity-conv.png)\n",
    "\n",
    "We can perform convolutions with Python by representing the input and kernel to be convolved as `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "kernel = [[0, 0, 0], \n",
    "          [0, 1, 0], \n",
    "          [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = convolve(x, kernel, mode='same')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = correlate2d(x, kernel, mode='same')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "This figure shows how a convolution can be used to essentially _translate_ the input by giving a weight to the value at a different position.\n",
    "\n",
    "![](../images/convolutions/translation-conv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "kernel = [[1, 0, 0], \n",
    "          [0, 0, 0], \n",
    "          [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = correlate2d(x, kernel, mode='same')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding \n",
    "\n",
    "The translation example immediately illustrates the problem with convolutions and the edges of an image: how can, for instance, the value for the last position be calculated, which does not have a 3 × 3 neighbourhood, and therefore also no value with which the weight of one can be multiplied? \n",
    "\n",
    "#### Valid padding\n",
    "One solution is to discard the edge cases in their entirety, producing no value at all at those positions at which the kernel cannot be validly applied to the position – called _valid padding_. An consequence of this approach, however, is that the output will have less values than the input, which may be undesirable. \n",
    "\n",
    "#### Same padding \n",
    "An alternative therefore is same padding, which ensures the output of the convolution is of a similar size to the input by filling in values for non-existing positions, such as zero, the average of the neighbourhood, or the nearest neighbour. \n",
    "\n",
    "![](../images/convolutions/padding-conv.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "kernel = [[1, 0, 0], \n",
    "          [0, 0, 0], \n",
    "          [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = correlate2d(x, kernel, mode='valid')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = correlate2d(x, kernel, mode='same')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example operations\n",
    "\n",
    "The convolutions we have seen so far were all on relatively small and simple `numpy` arrays. However, as the kernel _slides_ over the input, a $3\\times 3$ kernel can be applied on any input size, including images. This can lead to some interesting results. \n",
    "\n",
    "Let's load in an image and see what transformations we can apply to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve, correlate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "plt.gray()\n",
    "\n",
    "img = mpimg.imread('../images/dog.png')\n",
    "print(img.shape)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity operation\n",
    "\n",
    "First of all, the identity operation as seen before can be applied to the image. What output do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0, 0, 0], \n",
    "                   [0, 1, 0], \n",
    "                   [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = correlate(img, kernel)\n",
    "plt.imshow(filtered_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur\n",
    "\n",
    "Besides the identity operation and translation, there are some other operations we can perform with a convolution - such as a blurring operation. \n",
    "\n",
    "So what is blurring, exactly? Well, the purpose of blurring an image is to reduce the image's level of detail, but still maintain the rough outline or main content. This means each pixel needs to be edited in some way that it is noticeably different from before, but close enough to the original to give a rough idea of the original content. If we were to alter each pixel value based on the neighbouring pixels, the pixels would still contain information about the original value, but all neighbouring pixels would become more similar... like you would expect in a blurred image. \n",
    "\n",
    "So how would you construct a kernel for a blurring operation? Well, we have to define the neighbourhood of pixels to consider. Each of the pixels in the neighbourhood should contribute equally to the output value. Then, when we convolve a pixel with a the pixels surrounding it, every pixel contributes equally to the output value and the new value for the pixel will become a smooth mix of the pixel information surrounding it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUR_NEIGHBOURHOOD = 30\n",
    "\n",
    "kernel = np.ones((BLUR_NEIGHBOURHOOD, BLUR_NEIGHBOURHOOD)) \n",
    "kernel = kernel / np.sum(kernel)\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = correlate(img, kernel)\n",
    "plt.imshow(filtered_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsharp masking\n",
    "\n",
    "Besides blur, we can also sharpen an image with unsharp masking, although this is slightly more complicated. Imagine this: what is the opposite of a sharpened image? A blurry one. With a convolution, we can blur an image. If we take the original image, and subtract the blurriness, we should be left with the parts that are high-contrast, i.e. sharpened image! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUR_NEIGHBOURHOOD = 10\n",
    "\n",
    "# Create blurred image\n",
    "kernel = np.ones((BLUR_NEIGHBOURHOOD, BLUR_NEIGHBOURHOOD)) \n",
    "kernel = kernel / np.sum(kernel)\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = correlate(img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract blurred image from original\n",
    "sharpened_img = img - blurred_img\n",
    "plt.imshow(sharpened_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion blur\n",
    "\n",
    "Motion blur is a special type of blur that typically occurs when the camera is moved while an image is captured. We can replicate this with a convolution as well: for each pixel value we don't take all the pixel values in the neighbourhood into account, such as with regular blurring, but only in a specific direction. A kernel might look like: [1, 1, 1, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 30\n",
    "kernel = np.zeros((1, factor * 2))\n",
    "\n",
    "#kernel[:,0:factor] = 1\n",
    "kernel[0:factor] =1\n",
    "\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = correlate(img, kernel)\n",
    "plt.imshow(filtered_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "Convolutions may even be used for more advanced - and helpful in the context of image processing! - operations, such as edge detection. Firstly, we create a kernel that will help us detect the edges in the image. \n",
    "\n",
    "With this filter, the output will be 0 in a region where all pixel values are the same. This means regions in the image where pixel values change (edges) will be highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [-1, 8, -1], \n",
    "                   [-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = correlate(img, kernel)\n",
    "plt.imshow(filtered_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we want to highlight the found edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = filtered_img\n",
    "a[a > 0] = 1\n",
    "a[a < 0] = 0 \n",
    "plt.imshow(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Limitations of convolutions\n",
    "\n",
    "Convolutions are hugely useful for many image processing tasks. However, there is a limitation: a constraint for convolutions is that the same operation is applied to all pixels. If it didn't, the filter would be limited to particular perspectives/scales/objects etc.\n",
    "\n",
    "This means certain operations cannot be performed. \n",
    "\n",
    "![](../images/convolutions/dataaugmentation.png)\n",
    "\n",
    "Can you think of why these operations cannot be performed with a convolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
