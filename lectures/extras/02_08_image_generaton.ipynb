{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463fbdf7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../../css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78526ccb",
   "metadata": {},
   "source": [
    "# Generative Networks\n",
    "\n",
    "![footer_logo](../../images/logo.png)\n",
    "\n",
    "## Goal\n",
    "\n",
    "Classification is not the only computer vision task that can be performed by deep learning algorithms. \n",
    "\n",
    "In this notebook we shall discuss generative networks.\n",
    "\n",
    "## Program\n",
    "\n",
    "- [Generative networks]()\n",
    "- [Problem defintion]()\n",
    "- [Popular generative models]()\n",
    "- [Applications]()\n",
    "- [GANs]()\n",
    "- [Conditional GANs]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-problem",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Networks\n",
    "\n",
    "<center><img src=\"../../images/gans/gan_art.png\" width=\"900\"><center>\n",
    "\n",
    "[GAN art](https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-jurisdiction",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Problem definition\n",
    "\n",
    "## Generative models\n",
    "\n",
    "The amount of data in the world is boundless: what we see, hear and think can\n",
    "all be recorded and easily accessed\n",
    "\n",
    "Generative models: given (a large) training data, generate new data from the\n",
    "same distribution\n",
    "\n",
    "<center><img src=\"../../images/gans/real_generated.png\" width=\"800\"><center>\n",
    "\n",
    "https://openai.com/blog/generative-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-anthropology",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generative vs discriminative models\n",
    "\n",
    "So far we have focussed on discriminative models (e.g. classification)\n",
    "\n",
    "These models do not care how data was generated; they aim to classify the input, $P(y|x)$\n",
    "\n",
    "With generative models we try to learn *how* the data was generated. We then generate new data similar to (but not the same as) the existing ones.\n",
    "\n",
    "![](../../images/gans/image_from_vector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-dining",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Popular generative models\n",
    "\n",
    "- Generative Adversarial Networks (GANs)\n",
    "    - Zero-sum game of two players\n",
    "    - No explicit probability distribution\n",
    "- PixelCNN/RNN\n",
    "    - Image generation depends on previous pixels\n",
    "    - Explicit probability distribution\n",
    "- Variational Autoencoders (VAEs)\n",
    "    - Probabilistic variation of a traditional autoencoder (encoder network and decoder network)\n",
    "    - Approximates probability distribution\n",
    "- Normalizing Flows (NFs)\n",
    "    - Series of invertible & differentiable functions\n",
    "    - Explicit probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-corner",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applications: Data generation\n",
    "\n",
    "<img src=\"../../images/gans/notexist.png \" width=\"500\">\n",
    "\n",
    "\n",
    "[thispersondoesnotexist.com](https://thispersondoesnotexist.com)\n",
    "\n",
    "[thiscatdoesnotexist.com](https://thiscatdoesnotexist.com)\n",
    "\n",
    "[thisairbnbdoesnotexist.com](https://thisrentaldoesnotexist.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-index",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applications: text to image synthesis\n",
    "\n",
    "![](../../images/gans/text_to_image.png)\n",
    "\n",
    "https://github.com/hanzhanggit/StackGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-davis",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applications: style transfer\n",
    "\n",
    "![](https://github.com/junyanz/CycleGAN/raw/master/imgs/horse2zebra.gif) \n",
    "\n",
    "https://github.com/junyanz/CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-reservation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applications: deep fakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-vertex",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('AmUC4m6w1wo', width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-jewel",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GANs\n",
    "\n",
    "- A game between two neural networks (a discriminator D and a generator G)\n",
    "- G wants to fool D by generting realistic looking images\n",
    "- Meanwhile, D wants to detct fake images from G\n",
    "\n",
    "https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-transsexual",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GANs architecture\n",
    "\n",
    "![](../../images/gans/gan_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-enough",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpretable vector arithmetics\n",
    "\n",
    "<center><img src=\"../../images/gans/interpretable_vectors.png\" width=\"800\"><center>\n",
    "\n",
    "https://arxiv.org/abs/1511.06434"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-huntington",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Issue: mode collapse\n",
    "\n",
    "Generators collapse to produce only limited variations of the data\n",
    "\n",
    "![](../../images/gans/mode_collapse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-victor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional GANs\n",
    "\n",
    "If we include label information in the training process we can *control the type* of image that is generated.\n",
    "\n",
    "\n",
    "<center><img src=\"../../images/gans/conditional_gan.png\" width=\"600\"><center>\n",
    "\n",
    "https://arxiv.org/abs/1411.1784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-satisfaction",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Control the images that are generated\n",
    "\n",
    "![](../../images/gans/model_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-decimal",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Control the images that are generated\n",
    "\n",
    "![](../../images/gans/celeba_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408479f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we discussed generative networks.\n",
    "\n",
    "In particular we focussed on the GAN..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1e000",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The GAN consists of two networks:\n",
    "- Generator: generates realistic looking images,\n",
    "- Discriminator: detects whether an image is real or fake.\n",
    "\n",
    "Pros: State-of-the-art sample quality.\n",
    "  \n",
    "Cons: Difficult to train & do not learn the distribution of the data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
